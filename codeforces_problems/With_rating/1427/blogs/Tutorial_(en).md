# Tutorial_(en)


#### General comments

Broadly speaking, problems A-B-C-D were "div2 problems", while F-G-H were "strong grandmaster problems" (with E staying in the middle). I did not expect anyone to solve all the problems and thus I decided to give the scoring F+G=H (so that maybe someone would have solved H).   
  
 Many of the problems (A, C, D, E, G) admit multiple solutions. Sometimes the core of the solution is the same (C, D) and sometimes the solutions are truly different (A, E, G).   
  
 If you are an experienced participant, I would like to hear your opinion on the problems. Feel free to comment on this post or send me a private message.   
  
 

**Overview of the problemset** The easiest problem of the contest, *A-Avoiding Zero*, is about rearranging an array of numbers. It is intended as a very easy problem that still requires to think. Then, in *B-Chess Cheater* an intuitive (but nontrivial to prove) greedy approach is the way to go. *C-The Hard Work of Paparazzi* is a classical dynamic-programming problem with a twist. *D-Unshuffling a deck* is a constructive problem with a multitude of possible solutions (all somewhat similar). The difficulty difference between *D* and *E-Xum* is pretty large. Problem *E* asks to produce the number 1 (starting from a given number) using only the addition and the xor. A super-clean mathy approach is possible, but also a huge amount of (vastly different) randomized approaches (clean and not so clean) can lead to the solution.   
  
 Problems *F*, *G* have a similar difficulty. They are very different, so participants could choose which one to attack depending on their taste. Problem *F-Boring Card Game* asks to reconstruct the moves of a game given the final situation. Even if it looks as one more constructive problem, it is not. The crux of the problem is finding a criterion for the admissibility of a final situation and then noticing that a naive greedy algorithm produces a sequence of moves generating such final situation. It requires quite a bit of thinking, but then the implementation is trivial. Problem *G-One Billion Shades of Grey* has the clear smell of a flow, and indeed it is a flow problem! There are two possible approaches: either you have a clever idea, or you apply some advanced classical theory followed by a certain amount of optimizations. Compared to problem *F*, in *G* the ideas are more standard but the implementation is not immediate. Since the statement is extremely simple, it is possible that some versions of this problem are known (and I actually found at least one research paper considering something similar). I decided that the problem is beautiful enough to take the risk.   
  
 Finally we have *H-Prison Break* which is much harder than all other problems. Even if it is a variation over the well known [Cat and Mouse problem](https://codeforces.com/https://www.youtube.com/watch?time_continue=3&v=vF_-ob9vseM&feature=emb_logo), knowing the solution to the latter is not very helpful. It is a very nonstandard problem and a mix of mathematical insight and ability to handle an involved implementation is necessary to get accepted. 
#### Hints

**A**   
 **Hint 1**If a1+⋯+an=0, then the answer is NO.   
 **Hint 2**If a1+⋯+an≠0, then the answer is YES.   
 **Hint 3**If a1+⋯+an>0, then there is a rearrangement such that all prefix sums are strictly positive.   
    
 **B**   
 **Hint 1** The score is 2⋅#{wins}−#{winning_streaks}.    
 **Hint 2** You shall minimize the number of disjoint winning streaks.    
 **Hint 3** Fill the holes between winning streaks.    
    
 **C**   
 **Hint 1** Find an O(n2) dynamic-programming solution.    
 **Hint 2** The city is relatively small (i.e., r≤500).    
 **Hint 3** If j>i+2r then it is possible to go from the i-th appearance to the j-th appearance. Use this observation to optimize the O(n2) solution to O(nr).    
    
 **D**   
 **Hint 1** If two consecutive cards have consecutive numbers (in the right order) then you can "merge them".    
 **Hint 2** Consider only moves with small k.    
 **Hint 3** Find one move that increases by at least 1 the number of adjacent cards with consecutive numbers.    
    
 **E** There are two different solutions.   
 Solution 1:   
 **Hint 1** Write a number y coprime with x.    
 **Hint 2** Write the gcd between x and y (that is 1).    
 **Hint 3** Bezout's Theorem.    
 **Hint 4** If a=b+1 and b is even, then a∧b=1.    
 Solution 2:   
 **Hint 1** Keep a basis of the numbers that are the xor of a subset of the numbers on the blackboard (i.e., the xor-subspace generated by numbers on the blackboard).    
 **Hint 2** Make some random choices.    
 **Hint 3** If x=219+1, then it is necessary to write a number >1011 on the blackboard.    
 **Hint 4** Choose randomly two numbers from the xor-subspace and write their sum on the blackboard.    
    
 **F**   
 **Hint 1** Solve the problem without the constraint of alternating turns.    
 **Hint 2** The final situation is achievable if and only if it is achievable without alternating turns but with Giada taking the last turn.    
 **Hint 3** Use a greedy approach to take care of the alternating turns.    
    
 **G** There are two different solutions.   
 Solution 1:   
 **Hint 1** Solve the problem when the already painted tiles have only two shades.    
 **Hint 2** Formulate the problem as many min-cuts problems.    
 **Hint 3** Update the max-flow repeatedly to compute quickly enough the many min-cuts.    
 Solution2:   
 **Hint 1** Formulate the problem as a linear-programming problem.    
 **Hint 2** Compute the dual of the problem.    
 **Hint 3** Use the shortest-augmenting-path algorithm to compute the min-cost maxflow and optimize Dijkstra as much as possible (and simplify the graph as much as possible).    
    
 **H**   
 **Hint 1** Solve the problem with one guard instead of two.    
 **Hint 2** If the prisoner can escape, his strategy is easy.    
 **Hint 3** If the prisoner can escape, then he should go to a point on the climbable walls and either escape immediately or go toward one of two different points on the climbable walls and escape there.    
 **Hint 4** The prisoner can escape if and only if there are three points A < B < C on the climbable walls such that a guard cannot go from B to A as fast as the prisoner and a guard cannot go from B to C as fast as the prisoner.    
 **Hint 5** Binary search on the answer.    
 **Hint 6** Fix the sides where A and B are. The points B such that there is a good point A form an interval, determine the interval.    
 **Hint 7** Be optimistic and use ternary-search (or be less optimistic and solve a bunch of quadratic equations).    
    
#### Solutions

**A** 
### [1427A - Avoiding Zero](../problems/A._Avoiding_Zero.md "Codeforces Global Round 11")

First of all, notice that if the sum $a_1+a_2+\cdots+a_n$ is $0$, then, since $b$ is a rearrangement of $a$, it holds $b_1+b_2+\cdots+b_n=0$ and therefore the answer is NO.

On the other hand, if $a_1+a_2+\cdots+a_n\not=0$, then there is a valid array $b$. To show this, let us consider two cases. 

* If $a_1+a_2+\cdots+a_n > 0$, then $b$ can be chosen as the array $a$ sorted in decreasing order. In this way, for any $k=1,\dots, n$, it holds $b_{1}+\cdots+b_{k} > 0$. Let us prove it by dividing in two cases.
	+ If $b_{k}>0$, then also $b_{1},\dots,b_{k-1}$ are positive and therefore the sum is positive.
	+ If $b_{k}\le 0$, then also $b_{k+1},\dots,b_{n}$ are nonpositive and therefore $$b_{1}+\cdots+b_{k} = b_{1}+\cdots+b_{n} - (b_{k+1}+\cdots+b_{n}) \ge b_{1}+\cdots+b_{n} > 0\,.$$
* If $a_1+a_2+\cdots+a_n < 0$, then $b$ can be chosen as the array $a$ sorted in increasing order. The proof that this choice works is analogous to the previous case.

Alternative, randomized solution

If the sum $a_1+\cdots+a_n=0$, then the answer is NO (as explained in the previous solution). Otherwise, we repeatedly random shuffle the cities until all the conditions are satisfied.

It can be proven that a random shuffle works with probability $\ge\frac1n$ (see this comment for a [neat proof](Tutorial_(en).md?#comment-708739)).

Notice that the probability is exactly $\frac1n$ in at least two cases: 

* $a_1=a_2=\cdots=a_{n-1}=0$ and $a_n=1$.
* $a_1=a_2=\cdots=a_{m+1}=1$ and $a_{m+2}=a_{m+3}=\cdots=a_{2m+1}=-1$ (and $n=2m+1$).
 [Solution code](https://codeforces.com/contest/1427/submission/95156251)   
 **B** 
### [1427B - Chess Cheater](../problems/B._Chess_Cheater.md "Codeforces Global Round 11")

Notice that the score is equal to $$\texttt{score} = 2\cdot\texttt{#\{wins\}} - \texttt{#\{winning_streaks\}}\,,$$ where a winning streak is a maximal sequence of consecutive wins. 

In the explanation that follows, the variables $\texttt{#\{wins\}}$, $\texttt{#\{winning_streaks\}}$ are always related to the initial situation.

If $k+\texttt{#\{wins\}}\ge n$, then it is possible to win all games and therefore the answer is $2n-1$.

Otherwise, it is clear that we want to transform $k$ losses in $k$ wins. Thus, after the cheating, the number of wins will be $k+\texttt{#\{wins\}}$. Considering the formula above, it remains only to minimize the number of winning streaks. 

How can we minimize the number of winning streaks? It is very intuitive that we shall "fill" the gaps between consecutive winning streaks starting from the shortest gap in increasing order of length. This can be proven noticing that if $g$ gaps are not filled (i.e., after cheating this $g$ gaps still contain at least one loss each) then there are at least $g+1$ winning streaks.

The implementation goes as follows. With a linear scan we find the lengths of the gaps and then we sort them. Finally we count how many we can select with a sum of lengths $\le k$. The answer is $$2\cdot\big(k+\texttt{#\{wins\}}\big) - \texttt{#\{winning_streaks\}} + \texttt{#\{gaps_we_can_fill\}} \,.$$

The complexity of the solution is $O(n\log(n))$.

 [Solution code](https://codeforces.com/problemset/submission/1427/95156305)    
 **C** 
### [1427C - The Hard Work of Paparazzi](../problems/C._The_Hard_Work_of_Paparazzi.md "Codeforces Global Round 11")

This is a classical dynamic-programming task with a twist. For the solution to work it is fundamental that the city has a small diameter (i.e., $r$ shall not be large) and that there are not simultaneous appearances. 

We say that two celebrities $i<j$ are compatible if it is possible to take a photo of both, that is $$|x_i-x_j| + |y_i-y_j| \le t_j-t_i\,.$$

Let $ans_k$ be the maximum number of photos we can take of the first $k$ celebrities assuming that we take a photo of celebrity $k$ (if we cannot take a photo of celebrity $k$, then $ans_k:=-\infty$). It holds (assuming that we can take a photo of celebrity $k$) $$ans_k = 1 + \max\Big(0, \max_{\substack{1\le i < k,\\\ \text{$i$ is compatible with $k$}}} ans_i\Big)\,.$$ This formula produces immediately a solution with complexity $O(n^2)$: we compute $ans_k$ for $k$ that goes from $1$ to $n$; for each $k$ we need just to compute the maximum of $O(k)$ values.

How can we speed up this algorithm? The idea is that if $|k-i|$ is big, then $i$ and $k$ are always compatible. More precisely, if $k - i \ge 2r$ then $t_k-t_i \ge 2r$ (because there are no simultaneous appearances) and therefore $$|x_i-x_k| + |y_i-y_k| \le 2r \le t_k-t_i\,,$$ so $i$ is compatible with $k$. Applying this additional observation, we deduce $$ans_k = 1 + \max\Big(0, \max_{1\le i \le k-2r} ans_i, \max_{\substack{k-2r< i < k,\\\ \text{$i$ is_compatible_with $k$}}} ans_i\Big)\,.$$ Hence, if we bookkeep the maximum of $ans_i$ on prefixes, we can compute $ans_k$ in $O(r)$ and the overall complexity becomes $O(nr)$.

Alternative optimization It is also true that any optimal solution does not skip more than $4r$ consecutive celebrities (we leave the proof to the reader). Hence another possible optimization of the naïve formula is to take the maximum only over $k-4r\le i < k$.

 [Solution code](https://codeforces.com/problemset/submission/1427/95156325)    
 **D** 
### [1427D - Unshuffling a Deck](../problems/D._Unshuffling_a_Deck.md "Codeforces Global Round 11")

We say that a pair of consecutive cards in the deck is good if they have consecutive numbers (in the right order). Let $m$ be the number of good pairs. We show that, if the deck is not sorted, with one move we can increase $m$. Hence after at most $n-1$ moves it will hold $m=n-1$ and the deck will be sorted.

Since the deck is not sorted, there must be two indices $i<j$ such that $c_i=c_j+1$. Moreover, since $c_i > c_j$, there is $i\le t<j$ such that $c_t > c_{t+1}$. We split the deck as (with $k=4$ packets, or less if some of the packets are empty) $$D_1=[c_1,c_2,\dots,c_{i-1}],\ D_2=[c_i,c_{i+1},\dots, c_t],\ D_3=[c_{t+1},c_{t+2},\dots, c_j],\ D_4=[c_{j+1},c_{j+2},\dots, c_n]$$ and we perform the operation, obtaining the new deck $$[c_{j+1},c_{j+2},\dots, c_n, c_{t+1},c_{t+2},\dots, c_j, c_i,c_{i+1},\dots, c_t, c_1,c_2,\dots,c_{i-1}]\,.$$ In the new deck any pair that was good before the operation is still good (notice that $(c_t, c_{t+1})$ was not a good pair) and moreover the pair $(c_j,c_i)$ has become good. Therefore $m$ has increased as desired.

The limit on $n$ is so small that fundamentally any polynomial implementation gets accepted. Producing an $O(n^2)$ implementation is trivial, but it should also be possible to produce a pseudo-linear implementation.

 [Solution code](https://codeforces.com/problemset/submission/1427/95156351)    
 **E** 
### [1427E - Xum](../problems/E._Xum.md "Codeforces Global Round 11")

We present two different solutions. The first solution is by Anton, the second is mine. 

* The first solution is deterministic, it is fundamentally based on Bezout's Theorem and comes with a proof. It performs $\approx 100$ operations and writes numbers up to $O(x^3)$.
* The second solution is randomized, uses some xor-linear-algebra and comes without a proof. It performs $\approx 1000$ operations and writes numbers up to $O(x^2)$.

 There are many variations on the randomized solution, some of them being quite messy. The randomized solution we present is rather clean. Let us remark that, due to the constraint $x\le 999,\,999$, it is possible to test on your personal computer whether a certain algorithm is correct or not on all possible inputs.Deterministic, provable, "gcd" solution

Step 0: If $u$ is written on the blackboard, then we can write $nu$ on the blackboard with $O(\log(n))$ operations. 

How? Just using the sum operation as in the binary exponentiation (same algorithm, just replace multiplication with addition and exponentiation with multiplication).

Step 1: Write on the blackboard a number $y$ coprime with $x$.

Let $e\in\mathbb N$ be the largest integer such that $2^e\le x$ (i.e., $2^e$ is the largest bit of $x$). Notice that $y=(2^ex)\wedge x = (2^e+1)x - 2^{e+1}$ and therefore $gcd(x,y)=gcd(x,2^{e+1})=1$.

Step 2: Write $1=gcd(x,y)$ on the blackboard.

Let $a, b\ge 0$ be such that $ax-by=1$ ($a,b$ exist thanks to Bezout's theorem) with $b$ even (if $b$ is odd, we can add $y$ to $a$ and $x$ to $b$, getting an even $b$). Since $by$ is even, we have $ax\wedge by = 1$ and therefore we are able to write $1$ on the blackboard.

Randomized, unproven, linear-algebraic solution

We are going to talk about subspaces and basis; they shall be understood with respect to the operation xor on nonnegative integers.

The rough idea is to sample randomly two numbers from the subspace generated by the numbers currently on the blackboard and write their sum on the blackboard.

First, we choose the maximum number of bits $L$ that any number on the blackboard will ever have. A good choice is $2^L > x^2$ ($L=40$ works for any odd $x$ below $10^6$).

We iterate the following process until $1$ belongs to the subspace generated by the numbers written on the blackboard.

Let $S$ be the subspace generated by the numbers currently on the blackboard (i.e., the set of numbers that can be written as the xor of some numbers on the blackboard). Let $b_1,\dots, b_k$ be a basis for $S$. Randomly choosing $k$ bits $e_1,\dots,e_k$ we can produce a random element in $S$ as $$(e_1b_1)\wedge(e_2b_2)\wedge\cdots \wedge(e_kb_k) \,.$$ Let us choose two random numbers $u, v\in S$. 

* If $u+v \ge 2^L$, we choose a different pair of numbers.
* If $u+v\in S$ (we can check this in $O(k)$ since we know a basis for $S$), we choose a different pair of numbers.
* Otherwise, we add $u+v$ to $S$ and update the basis accordingly.

It turns out that this approach solves all odd values $3\le x\le 999,999$ instantaneously.

Could we choose a much smaller $L$? The answer is no. If $x=2^{19}+1$ then there is a xor-subspace $S$ that contains $x$ and such that if $u,v\in S$ and $u+v<2^{38}$ then $u+v\in S$. Notice that this implies that any strategy needs to write on the blackboard some "some big numbers". This is why any approach that avoids large numbers by design is doomed to fail.

Comment: Why should this solution work? Fundamentally, and this is the main idea of the problem, because the two operations $+$ and $\wedge$ are not related by any strange hidden structure. It would be a miracle if we could find a very big subspace for $\wedge$ that is closed also for $+$. And, since miracles are rare, here there is no miracle.

It should not be very hard to show that this solution works for any odd $x$, i.e. there is not a subspace that contains $x$ and is closed for sums that are below $2^L$ (if $2^L>x^2$). Nonetheless, I could not show it. On the other hand, I think that proving that this solution has a very good (expected) time-complexity is very hard, but I would be happy if someone proves me wrong.

 [Solution code](https://codeforces.com/problemset/submission/1427/95156382)    
 **F** 
### [1427F - Boring Card Game](../problems/F._Boring_Card_Game.md "Codeforces Global Round 11")

Before describing the solution, let us comment it.

The solution is naturally split in two parts: 

* Solving the problem without the "alternating turns" constraint.
* Noticing that a simple greedy is sufficient to take care of the "alternating turns" constraint.

The first part of the solution is a rather standard greedy approach with complexity $O(n)$. It is quite easy (considering that this is problem F) to guess that such a greedy approach works. On the other hand, the second part of the solution (i.e. noticing that Giada takes the last turn and this imposes a condition on the appropriate forest provided by the first part of the solution) is still a greedy with $O(n)$ complexity, but harder to guess and less standard.

The constraint on $n$ is very low as we did not want to implicitly hint towards a greedy approach. Moreover the greedy used in the first part of the solution can be replaced with an $O(n^3)$ dynamic-programming approach (which fits in the timelimit if implemented carefully) and the greedy described in the second part of the solution is slightly easier to implement with complexity $O(n^2)$.

Simpler problem, not alternating turns

Let us first consider a different (and easier) problem. Federico and Giada don't take turns, they take $3$ cards in the order they prefer (so at the end they may have a different number of cards). You are given a final situation (that is, the cards in Federico's pocket at the end) and you have to produce a sequence of moves that generates that set of cards at the end of the game. We assume that the final situation is fixed, hence each card is assigned to either Federico or Giada.

We are going to describe what is natural to call the stack-partitioning. The stack-partitioning is a particular partition of the deck into $2n$ groups of $3$ cards each (not necessarily contiguous) such that each group of cards contain cards taken by the same player (either all $3$ by Federico or all $3$ by Giada). A priori the stack-partitioning might fail, not producing the described partition (but we will se that if the set of cards in Federico's pocket is achievable then the stack-partitioning does not fail).

In order to create the stack-partitioning we iterate over the cards in the deck (hence the numbers from $1$ to $6n$) and we keep a stack of partial groups (i.e. of groups of less than $3$ cards). When we process a card, 

* if it was taken by the same player that took the cards in the group at the top of the stack, then we add it to that group. If the group has now $3$ cards, we pop it from the stack and it becomes a group in the stack-partitioning.
* if it was taken by the other player, we add it on top of the stack (as a group with just that card).

 If in the end the stack is empty, we say that the stack-partitioning works (otherwise we say that it fails).For example, if $n=2$ and the cards in Federico's pocket are $\{1,5,8,9,10,12\}$ then the stack-partitioning works and produces the partition $$\{\{2,3,4\},\{8,9,10\},\{6,7,8\},\{1,5,12\}\} \,.$$

The fundamental observation is:

Lemma: Let us fix a possible final situation. Let us perform the stack-partition starting with a nonempty stack, i.e. at the beginning the stack already contains some partial groups assigned to either Federico and Giada (these groups do not correspond to cards in the deck). At the end of the algorithm the stack will be as it was at the beginning, i.e., same number of partial groups, with same sizes and assigned to the same player.

proof: The proof is by induction on the number of cards in the deck. Since it is not hard and quite standard, we leave it to the reader.

Corollary: A final situation (i.e., a set of cards in Federico's pocket) is possible if and only if the stack-partitioning works. Moreover the stack-partitioning yields a way to produce the final situation.

proof: If the stack-partitioning works, then it clearly yields a way to produce the final situation (players take the groups of three cards in the same order as they are popped out of the stack). The other implication follows directly from the Lemma.

Original problem

Now, we can go back to the original statement. Let us notice a couple more properties of the stack-partitioning (both observations are valid both in the simpler version of the problem and in the harder): 

* The stack-partitioning produces a forest where each node is a group of $3$ cards taken by the same player (hence we will say that a node is owned by Federico or Giada). More precisely any group $G$ of $3$ cards is son of the group of $3$ cards at the top of the stack after $G$ is popped out (or $G$ is a root if the stack becomes empty). We will refer to this forest as the stack-forest. Notice that in the stack-forest two adjacent vertices are owned by different players.
* In any possible sequence of moves, the group taken in the last move intersects at least one root of the stack-forest. Indeed, the cards before the first card of the group can be taken independently from the others (without alternating turns) and therefore, thanks to the Lemma, when the first card of the group is processed the stack is empty (thus it belongs to a root).

We prove that a certain final situation is possible if and only if the stack-partitioning works and there is a root of the stack-forest that is owned by Giada.

First, if a situation is possible then the stack-partitioning works (because of the lemma). Moreover, since Giada performs the last move, thanks to the second property above, there must be a root of the stack-forest owned by Giada.

Let us now describe a greedy algorithm to produce a given final situation provided that the stack-partitioning works and there is a root owned by Giada in the stack-forest.

Notice that if we remove leaves from the stack-forest, alternating between nodes owned by Federico and Giada, we are actually performing a sequence of valid moves. The algorithm is the following: 

* When it is Federico's turn, we remove an arbitrary leaf owned by Federico.
* When it is Giada's turn we remove an arbitrary leaf owned by Giada taking care of not removing a root if there is only one root owned by Giada.

Why does the algorithm work? 

* When it is Federico's turn, since there is at least one root owned by Giada and the number of nodes owned by Federico and Giada is the same, there must be at least one leaf owned by Federico (recall that adjacent vertices have different owners).
* When it is Giada's turn, there are more nodes owned by Giada then by Federico, hence there is at least one leaf owned by Giada. Could it be that such a leaf is also a root and it is the only root owned by Giada? It can be the case only if that is in fact the only remaining vertex.
 [Solution code](https://codeforces.com/problemset/submission/1427/95156396)    
 **G** 
### [1427G - One Billion Shades of Grey](../problems/G._One_Billion_Shades_of_Grey.md "Codeforces Global Round 11")

We present two solutions: the first solution is mine, the second is by dacin21. 

* The first solution reduces the problem to the computation of $O(n)$ min-cuts and then computes the min-cuts with total complexity $O(n^3)$. This solution requires no advanced knowledge and it fits easily in the time-limit.
* The second solution solves the dual of the problem, which happens to be a min-cost flow. This shall be implemented with complexity $O(n^3)$ (or $O(n^3\log(n))$ and some optimizations) to fit in the time-limit.

We will solve the problem on a general graph (tiles = vertices, two tiles are adjacent if there is an edge between them).

Solution via many min-cuts

The solution is naturally split in two parts: 

* Reduce the problem to the computation of $O(n)$ min-cuts in the grid-graph (here $O(n)$ represents the number of already painted tiles).
* Compute all the min-cuts with overall complexity $O(n^3)$.

Reducing to many min-cuts

A natural way to come up with this solution is to consider the special case in which the painted tiles have only two colors. In such a case the problems is clearly equivalent to the min-cut. We show that something similar holds true in general.

Given a graph $(V, E)$, let $B$ be the set of vertices that are already painted (in our problem, $B$ contains the tiles on the boundary). Let us fix a choice of all the shades, that is a function $s:V\to\mathbb N$ such that $s(v)$ is the shade assigned to vertex $v$. Let TC be the total contrast. We have (using that, for $x\le y$, it holds $|x-y|=\sum_{k\ge 1}[x\le k\text{ and } y > k]$) $$\texttt{TC} = \sum_{(u,v)\in E} |s(u)-s(v)| = \sum_{k\ge 1} \\#\{(u,v)\in E:\ s(u)\le k,\, s(v)>k\} \,.$$ Given two disjoint subsets $U_1, U_2$ of vertices, let $mc(U_1, U_2)$ be the minimum-cut between these two set of vertices. Using the formula above, we have $$\texttt{TC} = \sum_{k\ge 1} mc(\{v\in V: s(v)\le k\}, \{v\in V: s(v)>k\}) \ge \sum_{k\ge 1} mc(\{v\in B: s(v)\le k\}, \{v\in B: s(v)>k\})\,.$$ Therefore, we have proven a lowerbound for the minimum total contrast. Let us show that this lowerbound can be achieved.

Given two disjoint subsets $U_1,U_2$, let $\mathcal{MC}(U_1,U_2)$ be the family of all the subsets $U_1\subseteq W\subseteq V\setminus U_2$ such that $mc(U_1, U_2)=mc(W,V\setminus W)$, i.e. the family of subsets achieving the minimum-cut. We are going to need the following lemma. Even though the proof is unilluminating, the statement is very intuitive.

Lemma: Take $U_1,U_2$ disjoint and $\tilde U_1,\tilde U_2$ disjoint, such that $U_1\subseteq \tilde U_1$ and $\tilde U_2\subseteq U_2$ (that is, $U_1$ grows and $U_2$ shrinks). If $W\in \mathcal{MC}(U_1,U_2)$ and $\tilde W\in \mathcal{MC}(\tilde U_1, \tilde U_2)$, then $W\cup \tilde W\in \mathcal{MC}(\tilde U_1, \tilde U_2)$.

proof. Given two disjoint sets $A,B\subseteq V$, let $c(A,B):=|(A\times B)\cap E|$ be the number of cross-edges. It holds (without using any assumption on $W$ or $\tilde W$) $$ c(W\cup \tilde W, (W\cup \tilde W)^c) - c(\tilde W, \tilde W^c) = c(W\setminus \tilde W, (W\cup \tilde W)^c) - c(\tilde W, W\setminus\tilde W) \\\ \quad\quad\quad\le c(W\setminus \tilde W,W^c) - c(W\cap \tilde W, W\setminus \tilde W) = c(W,W^c) - c(W\cap \tilde W, (W\cap \tilde W)^c)\,. $$ Since $W\in\mathcal MC(U_1,U_2)$ and $U_1\subseteq W\cap\tilde W\subseteq U_2^c$, the right-hand side is nonpositive. Hence also the left-hand side is nonpositive; thus we deduce $c(W\cup \tilde W, (W\cup \tilde W)^c) \le c(\tilde W, \tilde W^c)$ and therefore $W\cup\tilde W\in\mathcal{MC}(\tilde U_1, \tilde U_2)$.

Applying the lemma, we may find an increasing family of subsets $W_1\subseteq W_2\subseteq W_3\subseteq \cdots$ such that for all $k\ge 1$ it holds $$ W_k\in \mathcal{MC}(\{v\in B: s(v)\le k\}, \{v\in B: s(v)>k\}) \,.$$ It is easy to check that $s(v):=\min\{k: v\in W_k\}$ is a valid assignment of shades that achieves the minimum possible contrast (that is, it achieves equality in the formula above).

Hence, we may solve the problem running many maximum-flow algorithms. Running $O(n)$ times a max-flow algorithm should get time-limit-exceeded independently on how good your implementation of the maximum-flow is.

Remark. For those interested, the relation between min-cuts and the minimization of the contrast is very similar to the relation between the isoperimetric problem and the 1-Sobolev inequality (see [this wiki page](https://codeforces.com/https://en.wikipedia.org/w/index.php?title=Isoperimetric_inequality&oldid=973913971)). In the continuous setting, the strategy employed in this solution corresponds to the coarea formula.

Computing quickly many min-cuts

Our goal is computing $mc(\{v\in B: s(v)\le k\}, \{v\in B: s(v)>k\})$ for all values of $k$. The number of interesting values of $k$ is clearly $O(n)$. For simplicity, we assume that the interesting values of $k$ are contiguous and that all the tiles on the boundary have different shades.

Let us assume that we have computed, via a simple augmenting-path algorithm, a max-flow between $\{v\in B: s(v)\le k\}$ and $\{v\in B: s(v)> k\}$. In particular we are keeping the flow as a union of disjoint paths. We show how to update it to a max-flow between $\{v\in B: s(v)\le k+1\}$ and $\{v\in B: s(v)> k+1\}$ in $O(n^2)$ time (thus the overall complexity will be $O(n^3)$).

Passing from $k$ to $k+1$ we only need to transform a sink into a source (in particular the vertex such that $s(v)=k+1$ becomes a source). How shall we do that?. First of all we remove all the paths that ends in $v$ (there are at most $3$, which is the degree of $v$). Then we look for augmenting paths. Due to the optimality of the flow before the update, it is not hard to prove that there can be at most $6$ augmenting paths. The overall complexity of the update is $3n^2 + 6n^2 = O(n^2)$.

Solution via min-cost flow

The crucial point is formulating the problem as a linear programming problem and computing its dual, which somewhat magically turns out to be a min-cost flow. Then a very careful implementation of the min-cost flow algorithm is necessary to get accepted (with some optimizations, it is possible to get accepted with execution time below $1$ second).

Let $x_v$ be the shade of vertex $v$. For any edge $u\sim v$, let $c_{uv}$ be the contrast between $u$ and $v$. Then we have $$ c_{uv} \ge x_u-x_v \quad \text{ and }\quad c_{uv}\ge x_v-x_u \,, $$ and the total contrast is $ \sum c_{uv}$.

Hence, we have formulated the minimization of the total contrast as a linear programming problem. In this form, it's not clear how to solve it efficiently (the simplex algorithm would be way to slow).

Computing the dual problem is straight-forward (using well-known formulas) but a bit heavy on notation. In the end, the dual problem turns out to be the min-cost flow with the following parameters: 

* There is a source, connected to all the vertices $v$ already painted via an edge (from the source to $v$) with capacity $1$ and cost $x_v$.
* There is a sink, connected to all the vertices $v$ already painted via an edge (from $v$ to the sink) with capacity $1$ and cost $-x_v$.
* All the edges of the graph have capacity $1$ and cost $0$.

 The issue is that general-purpose min-cost flow algorithm have a rather bad complexity and are doomed to get time-limit-exceeded. The trick is to choose the simplest possible algorithm: use Dijkstra to repeatedly find a min-cost path from a source to a sink. Doing so yields an algorithm with complexity $O(n^3\log(n))$. This might get time-limit-exceeded or not depending on implementation details. Let us briefly describe two independent optimizations that may help in fitting in the time-limit: * Remove the edges between already painted vertices (taking care of the contrast generated by adjacent painted vertices).
* Use a radix-heap instead of a standard heap for Dijkstra.
 [Solution code](https://codeforces.com/problemset/submission/1427/95156412)    
 **H** 
### [1427H - Prison Break](../problems/H._Prison_Break.md "Codeforces Global Round 11")

We fix the unit of measure and say that the prisoner moves at $1$ meter per second.

Let us parametrize the boundary of the prison as follows (ignoring the very long, very high walls). Start walking with speed $1$ from $P_1$ towards $P_{n+1}$ staying on the prison wall and let $\gamma(t)$ be the point you are at after time $t$ (so $\gamma$ is a curve with speed $1$). Let $L$ be the total length of such curve (i.e., $\gamma(L)=P_{n+1}$). With an abuse of notation, we will denote with $\gamma$ also the image of $\gamma$ (i.e., the climbable walls).

A criterion for the prison break

The prisoner can escape if and only if there are three times $0\le t_1<t_2<t_3\le L$ such that $$\quad |\gamma(t_2)-\gamma(t_1)| < \frac{t_2-t_1}{v} \quad \text{ and } |\gamma(t_3)-\gamma(t_2)| < \frac{t_3-t_2}{v} \,.\tag{$\star$}$$

proof. 

If there are three times $t_1<t_2<t_3$ such that $(\star)$ holds, then the prisoner can escape. The strategy of the prisoner is as follows.

He begins by going (very close) to the point $\gamma(t_2)$. If there is not a guard there, he escapes. Otherwise, there must be a guard at (a point very close to) $\gamma(t_2)$. Without loss of generality we may assume that the other guard is at $\gamma(t)$ with $t<t_2$. Then the prisoner goes directly to $\gamma(t_3)$ and escapes from there. Notice that the prisoner reaches $\gamma(t_3)$ in $|\gamma(t_3)-\gamma(t_2)|$ seconds, while the closest guard (the one at $\gamma(t_2)$) needs $\frac{t_3-t_2}v$ seconds. The assumption guarantees that the prisoner reaches $\gamma(t_3)$ before the guard.

If there are not three such times such that $(\star)$ holds, then the guards have a strategy to avoid the prison break. This implication is harder; we split its proof into various steps.

The strategy of the guards is encoded by two functions $f_1,f_2$. Assume that we are given two functions $f_1,f_2:\mathcal Z\to [0,L]$, where $\mathcal Z$ denotes the interior of the prison, such that they are both $v$-Lipschitz (i.e., $|f(A)-f(B)|\le v|A-B|$) and, for any $0\le t\le L$, either $f_1(\gamma(t))=t$ or $f_2(\gamma(t))=t$ (or also both). Denoting with $Q$ the position of the prisoner, the guards may follow the following strategy (it is easy to adapt this strategy to the fact that initially the guards are at $P_1$, we leave it to the reader): 

* The first guard will always be at $\gamma(f_1(Q))$.
* The second guard will always be at $\gamma(f_2(Q))$.

 Notice that since the two functions are $v$-Lipschitz, it is possible for the guards to follow this strategy. Moreover, thanks to the properties of the functions $f_1,f_2$, when the prisoner reaches a point on the climbable walls there is always a guard waiting for him there. Extending Lipschitz functions. It remains to construct two such functions $f_1,f_2$. The idea is to define them on $\gamma$ and then extend them inside $\mathcal Z$ through a standard technique. Assume that we are able to define them on $\gamma$, it is well-known that a real-valued Lipschitz function defined on a subset of a metric space (the metric space is $\mathcal Z$, its subset is $\gamma$) can be extended to the whole metric space without increasing the Lipschitz constant (this may sound as abstract nonsense, but it's easy... prove it!).

From two functions to two subsets. The existence of the desired $f_1,f_2$ boils down to finding two functions on $\gamma$ that are $v$-Lipschitz and for each $0\le t\le L$ we have either $f_1(\gamma(t))=t$ or $f_2(\gamma(t))=t$. Let $\gamma_1,\gamma_2$ be the subsets of $\gamma$ where, respectively, $f_1(\gamma(t))=t$ and $f_2(\gamma(t))=t$. What can we say on the two subsets $\gamma_1$ and $\gamma_2$? Well, restricted on them, the function $\gamma(t)\mapsto t$ must be $v$-Lipschitz! Thus, applying again the extension argument described above, the problem reduces to finding two subsets $\gamma_1,\gamma_2$ of $\gamma$ such that $\gamma_1\cup\gamma_2=\gamma$ and the function $\gamma(t)\mapsto t$ is $v$-Lipschitz on $\gamma_1$ and $\gamma_2$.

Existence of the subsets via a bipartition argument. We have finally arrived at the core of the proof, constructing $\gamma_1$ and $\gamma_2$. Given two points $\gamma(s)$ and $\gamma(t)$, we say that they are compatible if $v|\gamma(s)-\gamma(t)| \ge |s-t|$. The conditions on $\gamma_1$ and $\gamma_2$ are equivalent to: 

* It holds $\gamma_1\cup\gamma_2=\gamma$.
* Any two points in $\gamma_1$ are compatible.
* Any two points in $\gamma_2$ are compatible.

 If we endow $\gamma$ with the graph structure induced by the incompatibility (there is an edge between two points if they are incompatible), then the existence of $\gamma_1$ and $\gamma_2$ is equivalent to the fact that such a graph is bipartite! Notice that the assumption of nonexistence of the three times such that $(\star)$ holds, is equivalent to the fact that there are not three points $\gamma(t_1),\gamma(t_2),\gamma(t_3)$ with $t_1<t_2<t_3$ such that $\gamma(t_1)$ is incompatible with $\gamma(t_2)$ and $\gamma(t_2)$ is incompatible with $\gamma(t_3)$. It is not hard (left to the reader) to check that this condition implies that the incompatibility-graph is bipartite.Computing the minimal speed $v$

In order to find the minimal $v$ such that the guards can avoid the prison break, we binary search the answer. Given a certain $v$, we must check whether there are three times $0\le t_1<t_2<t_3\le L$ such that $(\star)$ holds. 

We say that $t_2$ is left-incompatible if there is a $t_1<t_2$ such that $(\star)$ holds and we say that it is right-incompatible if there is a $t_3>t_2$ such that $(\star)$ holds. We have to check whether there is a time that is both left-incompatible and right-incompatible.

Let us assume that $\gamma(t_1)\in [P_i,P_{i+1}]$ and $\gamma(t_2)\in[P_j,P_{j+1}]$ with $i < j$. Under this additional constraint, characterizing the "left-incompatible" times $t_2$ reduces to finding all the points $\gamma(t_2)\in[P_j,P_{j+1}]$ such that $$ \min_{\gamma(t_1)\in[P_i,P_{i+1}]} |\gamma(t_2)-\gamma(t_1)|-\frac{t_2-t_1}{v} < 0 \,.$$ There are many different approaches to characterize the set of left-incompatible times $t_2$. The crucial observation that is common to all the approaches is that the set of left-incompatible $t_2$ is the union of $O(1)$ intervals (actually it is an interval, but this observation is not necessary for all the approaches). We present two such methods: 

* The first method, based on solving quadratic equations, needs some care to avoid precision issues/division by zero. The complexity is $O(1)$ (once $i$ and $j$ are fixed) and produces a complete algorithm with complexity $O(n^2\log(n)\log(\varepsilon^{-1}))$ (or a slightly easier to implement $O(n^3\log(\varepsilon^{-1}))$ that is super-fast.
* The second method, based on ternary search, is pretty straight-forward to implement but proving its correctness is rather hard. The complexity is $O(\log(\varepsilon^{-1})^2)$ and produces a complete algorithm with complexity $O(n^2\log(\varepsilon^{-1})^3 + n^3\log(\varepsilon^{-1}))$ which is rather slow in practice; some care might be necessary to get it accepted.

Since we will need them in both approaches, let us define $t^{\pm}_{12}$ as the values such that $\gamma(t_1^-)=P_i$, $\gamma(t_1^+)=P_{i+1}$, $\gamma(t_2^-)=P_j$, $\gamma(t_2^+)=P_{j+1}$.

Via quadratic equations. Consider the function $F(t_1,t_2):= |\gamma(t_2)-\gamma(t_1)|^2v^2-(t_2-t_1)^2$. We have to find the values $t_2\in[t_2^-,t_2^+]$ such that $$ \min_{t_1\in [t_1^-,t_1^+]} F(t_1, t_2) < 0\,.$$ Notice that $t_1\mapsto F(t_1,t_2)$ is a quadratic polynomial with positive leading coefficient. Hence the minimum is either at an extreme point $t_1\in \{t_1^-,t_1^+\}$ or at the point $t_1=:f(t_2)$ such that $\partial_{t_1}F(t_1,t_2)=0$. Moreover $t_2\mapsto F(t_1^-,t_2)$ and $t_2\mapsto F(t_1^+, t_2)$ and $t_2\mapsto F(f(t_2), t_2)$ are all quadratic polynomials, so the set of times $t_2$ where they are negative is either an interval or a union of two intervals (which can be found finding the roots of the appropriate quadratic equations). Since $f(t_2)\in[t_1^-,t_1^+]$ holds for $t_2$ in an interval (with easy to find extreme points), the solution is complete.

Let us remark that, even if everything seems elementary and easy, implementing this is not a cakewalk.

Via ternary search. Consider the function $G(t_1,t_2):= \frac{|\gamma(t_2)-\gamma(t_1)|}{t_2-t_1}$. We have to find the values $t_2\in[t_2^-,t_2^+]$ such that $$ \min_{t_1\in[t_1^-,t_1^+]} G(t_1, t_2) < v^{-1} \,.$$ The function $t_1\mapsto G(t_1,t_2)$ is unimodal, hence, given $t_2$, with a ternary search we may compute $$ \tilde G(t_2) := \min_{t_1\in[t_1^-, t_1^+]} G(t_1, t_2) \,.$$ Then, also the function $t_2\mapsto \tilde G(t_2)$ is unimodal, hence with a ternary search+binary search we may find the interval where it is below $v^{-1}$.

For a proof that the above functions are really unimodal, take a look at [this short pdf](https://codeforces.com/https://gofile.io/d/jU6X5j).

Implementing this second approach might be a bit tedious, but presents no real difficulty. Since this is quite slow, it might need some care to get accepted (for example, the arg-min of $\tilde G$ shall be computed only once and not for each binary-search iteration on $v$).

 [Solution code](https://codeforces.com/problemset/submission/1427/95156439) 